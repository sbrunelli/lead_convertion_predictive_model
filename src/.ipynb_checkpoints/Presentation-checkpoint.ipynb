{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lead Convertion Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:\\github\\lead_convertion_predictive_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-a36e41e4e189>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-a36e41e4e189>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    from 'data_cleaning.py' import DataCleaner\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_cleaning import DataCleaner\n",
    "from features_engineering import FeatureExtractor\n",
    "from model_selection import ModelSelector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data science pipeline in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_benchmark():\n",
    "    # read and clean the data\n",
    "    dc = DataCleaner()\n",
    "    data = dc.clean()\n",
    "\n",
    "    # separate target variable\n",
    "    target = data.pop('target')\n",
    "\n",
    "    # train test split\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data, target)\n",
    "\n",
    "    # featurize data\n",
    "    featurizer = FeatureExtractor()\n",
    "    X_train = featurizer.featurize(data_train)\n",
    "    X_test = featurizer.featurize(data_test)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X_train = X_train.reshape(-1, 1)\n",
    "    X_test = X_test.reshape(-1, 1)\n",
    "    y_train = np.array(target_train)\n",
    "    y_test = np.array(target_test)\n",
    "\n",
    "    # Select model\n",
    "    ms = ModelSelector()\n",
    "    best_model = ms.get_best_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Print model scores\n",
    "    ms.print_model_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      " #  Accuracy: 0.36150\n",
      " # Precision: 0.20000\n",
      " #    Recall: 0.00655\n",
      " #  F1 Score: 0.01268\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      " #  Accuracy: 0.66376\n",
      " # Precision: 0.72992\n",
      " #    Recall: 0.73501\n",
      " #  F1 Score: 0.73246\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      " #  Accuracy: 0.67394\n",
      " # Precision: 0.67712\n",
      " #    Recall: 0.91617\n",
      " #  F1 Score: 0.77872\n"
     ]
    }
   ],
   "source": [
    "run_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_cleaning import DataCleaner\n",
    "from features_engineering import FeatureExtractor\n",
    "from model_selection import ModelSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be the first real model we fit.\n",
    "\n",
    "Our goal here is to have a baseline that will serve as the starting point for our work and try to improve its performances step by step.\n",
    "\n",
    "The baseline model will contain 4 variables:\n",
    "\n",
    "1. Order.Entry.CHF\n",
    "2. Customer.Industry\n",
    "3. Solution\n",
    "4. Year\n",
    "\n",
    "In the process of doing that we will also:\n",
    "\n",
    "1. Delete rows with quantity != 1\n",
    "2. Delete rows for Copenhagen since too small a sample size\n",
    "3. Delete rows where Order.Entry.CHF has a z_value > 10\n",
    "4. Delete rows where Order.Entry.CHF < 1000\n",
    "\n",
    "This steps will be integrated in the DataCleaner class directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      " #  Accuracy: 0.36097\n",
      " # Precision: 0.22093\n",
      " #    Recall: 0.00802\n",
      " #  F1 Score: 0.01548\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      " #  Accuracy: 0.66217\n",
      " # Precision: 0.72283\n",
      " #    Recall: 0.74710\n",
      " #  F1 Score: 0.73477\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      " #  Accuracy: 0.67566\n",
      " # Precision: 0.67827\n",
      " #    Recall: 0.91725\n",
      " #  F1 Score: 0.77986\n"
     ]
    }
   ],
   "source": [
    "# read and clean the data\n",
    "dc = DataCleaner()\n",
    "data = dc.clean()\n",
    "\n",
    "# separate target variable\n",
    "target = data.pop('target')\n",
    "\n",
    "# train test split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target)\n",
    "\n",
    "# featurize data\n",
    "featurizer = FeatureExtractor()\n",
    "X_train = featurizer.featurize(data_train)\n",
    "X_test = featurizer.featurize(data_test)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "y_train = np.array(target_train)\n",
    "y_test = np.array(target_test)\n",
    "\n",
    "# Select model\n",
    "ms = ModelSelector()\n",
    "best_model = ms.get_best_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print model scores\n",
    "ms.print_model_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     30251\n",
       "85        1\n",
       "Name: Quantity, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Quantity.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30252, 34)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc = DataCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc.clean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
